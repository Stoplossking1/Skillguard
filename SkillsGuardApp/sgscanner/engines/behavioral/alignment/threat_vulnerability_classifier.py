import json
import logging
from typing import Any
from .alignment_llm_client import AlignmentLLMClient

class ThreatVulnerabilityClassifier:

    def __init__(self, model: str='gemini/gemini-2.0-flash', api_key: str | None=None, base_url: str | None=None):
        self.logger = logging.getLogger('sg.' + __name__)
        self.llm_client = AlignmentLLMClient(model=model, api_key=api_key, base_url=base_url)
        self._classification_prompt_template = self._get_classification_prompt()

    def _get_classification_prompt(self) -> str:
        return '# Threat vs Vulnerability Classification\n\nYou are a security expert analyzing a security finding to determine if it represents:\n- **THREAT**: Intentional malicious behavior (backdoor, data theft, deliberate deception)\n- **VULNERABILITY**: Unintentional coding mistake (oversight, missing validation, poor practice)\n- **UNCLEAR**: Cannot determine with confidence\n\n## Finding Details\n\n- **Threat Name**: {threat_name}\n- **Severity**: {severity}\n- **Summary**: {summary}\n- **Description Claims**: {description_claims}\n- **Actual Behavior**: {actual_behavior}\n- **Security Implications**: {security_implications}\n- **Dataflow Evidence**: {dataflow_evidence}\n\n## Classification Criteria\n\n**THREAT indicators** (malicious intent):\n- Deliberately hidden functionality (obfuscated code, misleading names)\n- Data exfiltration to attacker-controlled servers\n- Credential harvesting without legitimate purpose\n- Backdoor commands or remote code execution\n- Deliberate mismatch between description and behavior\n- Use of suspicious domains or encoded payloads\n\n**VULNERABILITY indicators** (coding mistakes):\n- Missing input validation\n- Overly permissive file/network access\n- Insufficient error handling\n- Documentation that\'s incomplete but not deliberately misleading\n- Common security anti-patterns\n- Reasonable explanation for the code behavior\n\n## Response Format\n\nRespond with valid JSON:\n\n```json\n{{\n    "classification": "THREAT" or "VULNERABILITY" or "UNCLEAR",\n    "confidence": "HIGH" or "MEDIUM" or "LOW",\n    "reasoning": "Explanation for the classification",\n    "key_indicators": ["indicator1", "indicator2", ...]\n}}\n```\n\nAnalyze the finding and provide your classification:\n'

    async def classify_finding(self, threat_name: str, severity: str, summary: str, description_claims: str, actual_behavior: str, security_implications: str, dataflow_evidence: str) -> dict[str, Any] | None:
        try:
            prompt = self._classification_prompt_template.format(threat_name=threat_name, severity=severity, summary=summary, description_claims=description_claims, actual_behavior=actual_behavior, security_implications=security_implications, dataflow_evidence=dataflow_evidence)
            response = await self.llm_client.verify_alignment(prompt)
            if not response or not response.strip():
                self.logger.warning('Empty response from LLM for threat/vulnerability classification')
                return None
            try:
                classification = json.loads(response)
                required_fields = ['classification', 'confidence', 'reasoning', 'key_indicators']
                if not all((field in classification for field in required_fields)):
                    self.logger.warning(f'Classification response missing required fields: {classification}')
                    return None
                valid_classifications = ['THREAT', 'VULNERABILITY', 'UNCLEAR']
                if classification['classification'] not in valid_classifications:
                    self.logger.warning(f'Invalid classification value: {classification['classification']}')
                    return None
                self.logger.debug(f'Classified as {classification['classification']} with {classification['confidence']} confidence')
                return classification
            except json.JSONDecodeError as e:
                self.logger.warning(f'Failed to parse classification JSON: {e}')
                self.logger.debug(f'Raw response: {response[:500]}')
                return None
        except Exception as e:
            self.logger.error(f'Error classifying finding: {e}', exc_info=True)
            return None
